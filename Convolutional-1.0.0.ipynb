{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from stilus.data.sets import MidiDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(5, 10, 4 )\n",
    "        self.conv2 = nn.Conv1d(10, 10, 4)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(10 * 13, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool1d(x,2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (conv1): Conv1d(5, 10, kernel_size=(4,), stride=(1,))\n",
      "  (conv2): Conv1d(10, 10, kernel_size=(4,), stride=(1,))\n",
      "  (fc1): Linear(in_features=130, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "conv_net = ConvNet()\n",
    "print(conv_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 5, 32])\n",
      "torch.Size([128, 5])\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(128, 5, 32)\n",
    "out = conv_net(input)\n",
    "print(input.shape)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.SGD(conv_net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_dataset = MidiDataset(\"training_data.npy\")\n",
    "dataloader = DataLoader(midi_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1000] loss: 11.461\n",
      "[1,  2000] loss: 10.898\n",
      "[1,  3000] loss: 10.464\n",
      "[1,  4000] loss: 10.244\n",
      "[1,  5000] loss: 10.057\n",
      "[1,  6000] loss: 9.762\n",
      "[1,  7000] loss: 9.642\n",
      "[1,  8000] loss: 9.465\n",
      "[2,  1000] loss: 9.434\n",
      "[2,  2000] loss: 9.430\n",
      "[2,  3000] loss: 9.394\n",
      "[2,  4000] loss: 9.408\n",
      "[2,  5000] loss: 9.304\n",
      "[2,  6000] loss: 9.397\n",
      "[2,  7000] loss: 9.304\n",
      "[2,  8000] loss: 9.380\n",
      "[3,  1000] loss: 9.264\n",
      "[3,  2000] loss: 9.281\n",
      "[3,  3000] loss: 9.322\n",
      "[3,  4000] loss: 9.248\n",
      "[3,  5000] loss: 9.190\n",
      "[3,  6000] loss: 9.071\n",
      "[3,  7000] loss: 9.160\n",
      "[3,  8000] loss: 9.188\n",
      "[4,  1000] loss: 9.021\n",
      "[4,  2000] loss: 9.158\n",
      "[4,  3000] loss: 9.064\n",
      "[4,  4000] loss: 9.033\n",
      "[4,  5000] loss: 9.068\n",
      "[4,  6000] loss: 9.125\n",
      "[4,  7000] loss: 8.995\n",
      "[4,  8000] loss: 8.937\n",
      "[5,  1000] loss: 8.976\n",
      "[5,  2000] loss: 8.927\n",
      "[5,  3000] loss: 8.928\n",
      "[5,  4000] loss: 8.927\n",
      "[5,  5000] loss: 8.857\n",
      "[5,  6000] loss: 8.820\n",
      "[5,  7000] loss: 8.689\n",
      "[5,  8000] loss: 8.924\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[:,:,0:32], data[:,:,32]\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = conv_net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 1000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: tensor([[-1.0344e-04,  3.5378e-04, -3.3060e-04,  4.3155e-04,  7.8967e+00],\n",
      "        [-1.0344e-04,  3.5378e-04, -3.3060e-04,  4.3155e-04,  7.8967e+00]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "labels: tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "pred: tensor([[-1.0344e-04,  3.5378e-04, -3.3060e-04,  4.3155e-04,  7.8967e+00],\n",
      "        [-1.0344e-04,  3.5378e-04, -3.3060e-04,  4.3155e-04,  7.8967e+00]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "labels: tensor([[ 0.,  0.,  0., 63., 75.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.]])\n",
      "pred: tensor([[-1.0344e-04,  3.5378e-04, -3.3060e-04,  4.3155e-04,  7.8967e+00],\n",
      "        [-1.0344e-04,  3.5378e-04, -3.3060e-04,  4.3155e-04,  7.8967e+00]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "labels: tensor([[ 0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 69., 72., 75.]])\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(dataloader, 0):\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    inputs, labels = data[0:2,:,0:32], data[0:2,:,32]\n",
    "    print(\"pred:\", conv_net(inputs))\n",
    "    print(\"labels:\", labels)\n",
    "    if i == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
